{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "094a4716",
   "metadata": {},
   "source": [
    "# Train and Predict Pawpularity using VGG16 + Regression methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4854a2cb",
   "metadata": {},
   "source": [
    "If you want run this code, please download dataset from [kaggle](https://www.kaggle.com/competitions/petfinder-pawpularity-score/data) and put all data into data folder."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "130acef5",
   "metadata": {},
   "source": [
    "### Import packages below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4c01177-02ee-4795-a5af-436f4a7709c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pacakages.\n",
    "# Packages to process csv files.\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Packages to process images.\n",
    "# tqdm is a progress bar.\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Packages for model training.\n",
    "from keras.utils import load_img, img_to_array\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# LinearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# SVR\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# XGBoost\n",
    "import xgboost\n",
    "\n",
    "# Lightgbm\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "# Packages for model persistence\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da25fd18",
   "metadata": {},
   "source": [
    "### Explore data in train.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4869a2b-08c3-4a3f-b6b9-71cf1a79210a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Id', 'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur', 'Pawpularity']\n",
      "100\n",
      "1\n",
      "38.03904358353511\n",
      "33.0\n"
     ]
    }
   ],
   "source": [
    "# Read the csv file.\n",
    "train_csv = pd.read_csv('./data/train.csv')\n",
    "\n",
    "# Explore the csv file\n",
    "headers = list(train_csv.columns)\n",
    "print(headers)\n",
    "\n",
    "# As we extract features from image using VGG. We do not use features showed here.\n",
    "# We only care about `Id` and `Pawpularity`. Explore the range of `Pawpularity`\n",
    "df_pawpularity = train_csv['Pawpularity']\n",
    "df_max = df_pawpularity.max()\n",
    "df_min = df_pawpularity.min()\n",
    "df_mean = df_pawpularity.mean()\n",
    "df_median = df_pawpularity.median()\n",
    "\n",
    "print(df_max)\n",
    "print(df_min)\n",
    "print(df_mean)\n",
    "print(df_median)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e293ea0",
   "metadata": {},
   "source": [
    "### Read all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df5c4171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images is: 9912\n"
     ]
    }
   ],
   "source": [
    "# Read image files.\n",
    "image_path = './data/train'\n",
    "image_files = os.listdir(image_path)\n",
    "print(f'Total number of images is: {len(image_files)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd2d3915",
   "metadata": {},
   "source": [
    "### Extract image features using VGG16 pre-trained by imagenet.\n",
    "\n",
    "- Remove classifier layers and using weights trained using imagenet.\n",
    "- It's very important to normalize images. This will make the matrix sparse. If don't do this, the parameters will become to huge (2.2TB) that cannot be easy handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6659187a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 128, 128, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 128, 128, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912/9912 [00:31<00:00, 317.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310/310 [==============================] - 15s 32ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = VGG16(weights='imagenet', input_shape = (128, 128, 3), include_top=False)\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Process images to conform the input size of VGG16.\n",
    "train_images = []\n",
    "for image_file in tqdm(image_files):\n",
    "    full_path = os.path.join(image_path, image_file)\n",
    "    img = load_img(full_path, target_size=(128, 128, 3))\n",
    "    image_array = img_to_array(img) / 255\n",
    "    \n",
    "    train_images.append(image_array)\n",
    "\n",
    "\n",
    "train_images = np.array(train_images)    \n",
    "\n",
    "features = model.predict(train_images)\n",
    "\n",
    "expand_features = features.reshape(features.shape[0], -1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d11d8030",
   "metadata": {},
   "source": [
    "### Normalize the pawpulrity.\n",
    "\n",
    "In previous cell, we find that the range of pawpularity is `1-100`. Normalize it to `0-1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1333ef5-7520-4147-8bb9-04a389f8fbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_csv['Pawpularity'] / 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50abfe6f",
   "metadata": {},
   "source": [
    "### Use k-fold cross validation\n",
    "\n",
    "This method is to make sure that the evaluation of model is rely on how we pick the data.\n",
    "\n",
    "K-fold cross validation method procedure:\n",
    "\n",
    "- Randomly, split the entire dataset into k number folds.\n",
    "- For each fold in the dataset, build the model on `k-1` folds of the dataset. Then, test the model to check the effectiveness for kth fold.\n",
    "- Repeat this until each of the k-folds has served as the test-set\n",
    "- The average of k recorded accuracy is called the cross-validation accuracy and will serve as a performance metric for the model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4741e4db-dfd5-479a-a4d9-18b73c624108",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 4\n",
    "kf = KFold(n_splits = FOLD)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05a76268",
   "metadata": {},
   "source": [
    "### Use Linear Regression to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "653e1f4a-030c-48ae-b26b-35430eae61eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:02, 62.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [02:05, 63.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [03:09, 63.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [04:13, 63.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 0.98\n",
      "averge cross validation accuracy for 4 folds is: 0.9842033578723071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "all_rmse = []\n",
    "\n",
    "for train_index,test_index in tqdm(kf.split((train_images))):\n",
    "    # Train linear regression model.\n",
    "    lr.fit(expand_features[train_index],train_label[train_index])\n",
    "    # Predict pawpularity for evaluation.\n",
    "    pred_y = lr.predict(expand_features[test_index]);\n",
    "    y_true = train_label[test_index]\n",
    "\n",
    "    # Use mean squared error as evaluation metric\n",
    "    rmse = mean_squared_error(pred_y, y_true, squared=False)\n",
    "    all_rmse.append(rmse)\n",
    "\n",
    "    # Print rmse for one iteration.\n",
    "    print('RMSE {:.2f}'.format(rmse))\n",
    "\n",
    "# Print averge cross validation accuracy.\n",
    "print(f'averge cross validation accuracy for {FOLD} folds is: {sum(all_rmse) / len(all_rmse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a725aa8e",
   "metadata": {},
   "source": [
    "### Linear Regression Model Persistence\n",
    "\n",
    "Using `pickle` package to dump weights to local file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dea79ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('lr.pkl','wb') as f:\n",
    "    pickle.dump(lr,f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c19f670",
   "metadata": {},
   "source": [
    "### Use SVR to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37c4a3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:43, 103.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [03:33, 107.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [05:19, 106.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [07:05, 106.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 0.20\n",
      "averge cross validation accuracy for 4 folds is: 0.20257650802425914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "svr = SVR(C=0.01,kernel='poly')\n",
    "\n",
    "all_rmse = []\n",
    "\n",
    "for train_index,test_index in tqdm(kf.split((train_images))):\n",
    "    \n",
    "    svr.fit(expand_features[train_index],train_label[train_index])\n",
    "    pred_y = svr.predict(expand_features[test_index]);\n",
    "    y_true = train_label[test_index]\n",
    "\n",
    "    rmse = mean_squared_error(pred_y,y_true,squared = False)\n",
    "    all_rmse.append(rmse)\n",
    "    \n",
    "    print('RMSE {:.2f}'.format(rmse))\n",
    "\n",
    "# Print averge cross validation accuracy.\n",
    "print(f'averge cross validation accuracy for {FOLD} folds is: {sum(all_rmse) / len(all_rmse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a093800d",
   "metadata": {},
   "source": [
    "### SVR Model Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c27115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('svr.pkl','wb') as f:\n",
    "    pickle.dump(svr,f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "761e32dc",
   "metadata": {},
   "source": [
    "### Use XGBoost to train model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28d9178e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:34, 34.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [01:08, 34.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [01:43, 34.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [02:17, 34.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 0.20\n",
      "averge cross validation accuracy for 4 folds is: 0.19752659695873082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = xgboost.XGBRegressor(learning_rate=0.01, max_depth=4, n_estimators = 100)\n",
    "\n",
    "all_rmse = []\n",
    "\n",
    "for train_index, text_index in tqdm(kf.split((train_images))):\n",
    "\n",
    "    xgb.fit(expand_features[train_index], train_label[train_index])\n",
    "    pred_y = xgb.predict(expand_features[test_index]);\n",
    "    y_true = train_label[test_index]\n",
    "    \n",
    "    rmse = mean_squared_error(pred_y,y_true,squared = False)\n",
    "    all_rmse.append(rmse)\n",
    "\n",
    "    print('RMSE {:.2f}'.format(rmse))\n",
    "\n",
    "# Print averge cross validation accuracy.\n",
    "print(f'averge cross validation accuracy for {FOLD} folds is: {sum(all_rmse) / len(all_rmse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6dc29889",
   "metadata": {},
   "source": [
    "### XGBoost Model Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1da928e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('xgb.pkl','wb') as f:\n",
    "    pickle.dump(xgb,f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45b28a70",
   "metadata": {},
   "source": [
    "### Use lightgbm to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a806ca58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:16, 16.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:33, 16.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:49, 16.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [01:05, 16.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 0.20\n",
      "averge cross validation accuracy for 4 folds is: 0.20217341801761837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "lgbm = LGBMRegressor(learning_rate= 0.01, max_depth=4, n_estimators=100)\n",
    "\n",
    "all_rmse = []\n",
    "\n",
    "for train_index, test_index in tqdm(kf.split(train_images)):\n",
    "\n",
    "    lgbm.fit(expand_features[train_index], train_label[train_index])\n",
    "    pred_y = lgbm.predict(expand_features[test_index]);\n",
    "    y_true = train_label[test_index]\n",
    "    \n",
    "    rmse = mean_squared_error(pred_y, y_true, squared = False)\n",
    "    all_rmse.append(rmse)\n",
    "\n",
    "    print('RMSE {:.2f}'.format(rmse))\n",
    "\n",
    "# Print averge cross validation accuracy.\n",
    "print(f'averge cross validation accuracy for {FOLD} folds is: {sum(all_rmse) / len(all_rmse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f11a043e",
   "metadata": {},
   "source": [
    "### Lightgbm Model Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb9d5d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lgbm.pkl','wb') as f:\n",
    "    pickle.dump(lgbm,f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "570f4315",
   "metadata": {},
   "source": [
    "### Predict pawpularity using each model for Pidan\n",
    "- Firstly, read all images that should be predicted\n",
    "- Secondly, using VGG16 above to extract feature.\n",
    "- Thirdly, load linear regression weights and predict.\n",
    "- Fourthly, load svr weights and predict.\n",
    "- Fifthly, load xgboost weights and predict.\n",
    "- Finally, load lighbgm weights and predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b30f8107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 76.89it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_dir = './data/pidan'\n",
    "predict_images_list = os.listdir(predict_dir)\n",
    "\n",
    "predict_images = []\n",
    "\n",
    "for image in tqdm(predict_images_list):\n",
    "    full_path = os.path.join(predict_dir, image)\n",
    "    img = load_img(full_path, target_size=(128, 128, 3))\n",
    "    image_array = img_to_array(img) / 255\n",
    "    predict_images.append(image_array)\n",
    "\n",
    "predict_images = np.array(predict_images)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a55831a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "test_features = model.predict(predict_images)\n",
    "expand_features = test_features.reshape(test_features.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89813530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.49108666  0.7700281  -0.567711  ]\n"
     ]
    }
   ],
   "source": [
    "lr_weights = './lr.pkl'\n",
    "with open(lr_weights, 'rb') as file:\n",
    "    lr = pickle.load(file)\n",
    "\n",
    "prediction = lr.predict(expand_features)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "811817b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32936038 0.33635866 0.30284451]\n"
     ]
    }
   ],
   "source": [
    "svr_weights = './svr.pkl'\n",
    "with open(svr_weights, 'rb') as file:\n",
    "    svr = pickle.load(file)\n",
    "\n",
    "prediction = svr.predict(expand_features)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3cbfb111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41824916 0.40569213 0.42035866]\n"
     ]
    }
   ],
   "source": [
    "xgb_weights = './xgb.pkl'\n",
    "with open(xgb_weights, 'rb') as file:\n",
    "    xgb = pickle.load(file)\n",
    "\n",
    "prediction = xgb.predict(expand_features)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "842c4cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.369031   0.36742713 0.37338372]\n"
     ]
    }
   ],
   "source": [
    "lgbm_weights = './lgbm.pkl'\n",
    "with open(lgbm_weights, 'rb') as file:\n",
    "    lgbm = pickle.load(file)\n",
    "\n",
    "prediction = lgbm.predict(expand_features)\n",
    "print(prediction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7172e3dc",
   "metadata": {},
   "source": [
    "### Generate `submission.csv` for test using SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b087a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv = pd.read_csv('./data/test.csv')\n",
    "test_images_dir = './data/test'\n",
    "test_images_list = os.listdir(test_images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f045847c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 269.77it/s]\n"
     ]
    }
   ],
   "source": [
    "test_images = []\n",
    "for image in tqdm(test_images_list):\n",
    "    path = os.path.join(test_images_dir, image)\n",
    "    img = load_img(full_path, target_size=(128, 128, 3))\n",
    "    image_array = img_to_array(img) / 255\n",
    "    test_images.append(image_array)\n",
    "    \n",
    "test_images = np.array(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ab76bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "test_features = model.predict(test_images)\n",
    "expand_features = test_features.reshape(test_features.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f64b750a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './svr.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m svr_weights \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./svr.pkl\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(svr_weights, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m      4\u001b[0m     svr \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(file)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './svr.pkl'"
     ]
    }
   ],
   "source": [
    "svr_weights = './svr.pkl'\n",
    "\n",
    "with open(svr_weights, 'rb') as file:\n",
    "    svr = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "487091c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = svr.predict(expand_features)\n",
    "submission = pd.DataFrame()\n",
    "submission['Id'] = test_csv['Id']\n",
    "# Resize pawpularity from `0-1` to `1-100`\n",
    "submission['Pawpularity'] = prediction * 100\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "c3bb5cd2b06cc3c1780e1713d5e88a2b74d7f08ac789b0db90f60e54a7f815bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
